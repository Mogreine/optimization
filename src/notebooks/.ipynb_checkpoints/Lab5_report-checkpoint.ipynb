{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5\n",
    "## Задание\n",
    "1. Произвести масштабирование признаков (scaling).\n",
    "2. С использованием библиотеки scikit-learn написать программу с использованием алгоритмов кластеризации данных, позволяющую разделить исходную выборку на классы, соответствующие предложенной вариантом задаче.\n",
    "3. Провести эксперименты и определить наилучший алгоритм кластеризации, параметры алгоритма. Необходимо использовать не менее 3-х алгоритмов. Данные экспериментов необходимо представить в отчете.\n",
    "\n",
    "Данные: Mice Protein Expression.\n",
    "\n",
    "## Выполнение работы\n",
    "### Пункт 1\n",
    "Импортируем нужные для работы библиотеки и прочитаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Tuple\n",
    "from numpy import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, Perceptron\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.cluster import KMeans, MeanShift, AgglomerativeClustering, SpectralClustering, FeatureAgglomeration\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "target_feature = 'class'\n",
    "\n",
    "metric = adjusted_rand_score\n",
    "\n",
    "data = pd.read_excel('../../data/lab5.xls')\n",
    "\n",
    "y = data[target_feature]\n",
    "data.drop([target_feature], axis=1, inplace=True)\n",
    "X = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала необходимо обработать данные. В сете имеются 3 столбца, которые по сути в сочетании с друг другом образуют целевой столбец, так что их уберем, ибо цель стоит выделить классы по протеинам. На одних только этих столбцах любой алгорит даст иделаьный результат, так что такая кластеризация не представляет интереса. Также имеется столбец `MouseID`, который не несет в себе никакой информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['MouseID', 'Genotype', 'Treatment', 'Behavior'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "X.dropna(axis=0, inplace=True)\n",
    "\n",
    "y_init = y.copy()\n",
    "y = y.iloc[X.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь же произведем масштабирование признаков, но в этот раз будем использовать `MinMaxScaler`, который является функцией $f: X \\to (0, 1)$. Выбор обоснован тем, что подобное масштабирование лучше разделяет признаки между собой, а учитывая, что классы, которые предстоит разделять, достаточно похожи, это является очень важным фактором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X[list(X)] = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 2\n",
    "Воспользуемся алгоритмом `KMeans`, чтобы кластеризовать данные. Метрикой же будет `adjusted_rand_score`, ибо ее значение лежит в диапазоне $[-1, 1]$, что позволит проще определить насколько хороша или плоха модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans score: 0.202\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(X, y, model, **params):\n",
    "    model = model.set_params(**params)\n",
    "    preds = model.fit_predict(X)\n",
    "    score = metric(y, preds)\n",
    "    return score\n",
    "    \n",
    "    \n",
    "def try_km(X, y, **args):\n",
    "    base_params = {\n",
    "        'n_clusters': 8,\n",
    "        'verbose': 0,\n",
    "        'random_state': 7,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    params = { **base_params, **args }\n",
    "\n",
    "    model = KMeans()\n",
    "    score = get_accuracy(X, y, model, **params)\n",
    "    print('Kmeans score: {:.3f}'.format(score))\n",
    "    \n",
    "try_km(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат не является очень хорошим, поэтому есть смысл попробовать другие алгоритмы кластеризации, а также проанализировать данные тщательнее.\n",
    "\n",
    "### Пункт 3\n",
    "Для начала попробуем другие алгоритмы.\n",
    "\n",
    "Проверим `GaussianMixture`, ибо обычно этот алгоритм лучше справляется с кучными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian mixture score: 0.205\n"
     ]
    }
   ],
   "source": [
    "def try_gm(X, y, **args):\n",
    "    base_params = {\n",
    "        'n_components': 8,\n",
    "        'random_state': 7\n",
    "    }\n",
    "    params = { **base_params, **args }\n",
    "\n",
    "    model = GaussianMixture()\n",
    "    score = get_accuracy(X, y, model, **params)\n",
    "    print('Gaussian mixture score: {:.3f}'.format(score))\n",
    "\n",
    "try_gm(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не многим лучше, чем `KMeans`. Давайте теперь попробуем один из иерархальных алгоритмов - `AgglomerativeClustering`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agglomerative clustering score: 0.200\n"
     ]
    }
   ],
   "source": [
    "def try_ac(X, y, **args):\n",
    "    base_params = {\n",
    "        'n_clusters': 8\n",
    "    }\n",
    "    params = { **base_params, **args }\n",
    "    \n",
    "    model = AgglomerativeClustering()\n",
    "    score = get_accuracy(X, y, model, **params)\n",
    "    print('Agglomerative clustering score: {:.3f}'.format(score))\n",
    "\n",
    "try_ac(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично. Все 3 алгоритма дают плюс минус один и тот же результат, так что скорее всего нам нужно лучше поработать с данными.\n",
    "\n",
    "В части обработки данных мы удаляем все семплы, которые содержат нулевые значения, посмотрим сколько всего мы удалили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples deleted: 528 = 48.89%\n"
     ]
    }
   ],
   "source": [
    "print(f'Total samples deleted: {data.shape[0] - X.shape[0]} = {(data.shape[0] - X.shape[0]) / data.shape[0] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что мы удаляем практически половину данных, что точно не является лучшим решением. Давайте посмотрим, сколько пропусков содержится по колонкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "col #0, nans: 0.28%\n",
      "col #1, nans: 0.28%\n",
      "col #2, nans: 0.28%\n",
      "col #3, nans: 0.28%\n",
      "col #4, nans: 0.28%\n",
      "col #5, nans: 0.28%\n",
      "col #6, nans: 0.28%\n",
      "col #7, nans: 0.28%\n",
      "col #8, nans: 0.28%\n",
      "col #9, nans: 0.28%\n",
      "col #10, nans: 0.28%\n",
      "col #11, nans: 0.28%\n",
      "col #12, nans: 0.28%\n",
      "col #13, nans: 0.28%\n",
      "col #14, nans: 0.28%\n",
      "col #15, nans: 0.28%\n",
      "col #16, nans: 0.28%\n",
      "col #17, nans: 0.28%\n",
      "col #18, nans: 0.28%\n",
      "col #19, nans: 0.28%\n",
      "col #20, nans: 0.28%\n",
      "col #21, nans: 0.28%\n",
      "col #22, nans: 0.28%\n",
      "col #23, nans: 1.67%\n",
      "col #24, nans: 0.28%\n",
      "col #25, nans: 0.28%\n",
      "col #26, nans: 0.28%\n",
      "col #27, nans: 0.65%\n",
      "col #28, nans: 0.28%\n",
      "col #29, nans: 0.28%\n",
      "col #30, nans: 0.28%\n",
      "col #31, nans: 1.67%\n",
      "col #32, nans: 0.28%\n",
      "col #33, nans: 0.28%\n",
      "col #34, nans: 0.28%\n",
      "col #35, nans: 0.28%\n",
      "col #36, nans: 0.28%\n",
      "col #37, nans: 0.28%\n",
      "col #38, nans: 0.28%\n",
      "col #39, nans: 0.28%\n",
      "col #40, nans: 0.28%\n",
      "col #41, nans: 0.28%\n",
      "col #42, nans: 0.28%\n",
      "col #43, nans: 0.00%\n",
      "col #44, nans: 0.00%\n",
      "col #45, nans: 0.00%\n",
      "col #46, nans: 0.00%\n",
      "col #47, nans: 0.00%\n",
      "col #48, nans: 0.00%\n",
      "col #49, nans: 0.00%\n",
      "col #50, nans: 0.00%\n",
      "col #51, nans: 0.00%\n",
      "col #52, nans: 0.00%\n",
      "col #53, nans: 0.00%\n",
      "col #54, nans: 0.00%\n",
      "col #55, nans: 0.00%\n",
      "col #56, nans: 0.00%\n",
      "col #57, nans: 0.00%\n",
      "col #58, nans: 0.00%\n",
      "col #59, nans: 0.00%\n",
      "col #60, nans: 0.00%\n",
      "col #61, nans: 0.00%\n",
      "col #62, nans: 0.00%\n",
      "col #63, nans: 0.00%\n",
      "col #64, nans: 0.00%\n",
      "col #65, nans: 0.00%\n",
      "col #66, nans: 0.00%\n",
      "col #67, nans: 0.00%\n",
      "col #68, nans: 19.72%\n",
      "col #69, nans: 26.39%\n",
      "col #70, nans: 0.00%\n",
      "col #71, nans: 6.94%\n",
      "col #72, nans: 0.00%\n",
      "col #73, nans: 16.67%\n",
      "col #74, nans: 19.44%\n",
      "col #75, nans: 25.00%\n",
      "col #76, nans: 0.00%\n"
     ]
    }
   ],
   "source": [
    "cols = list(data)\n",
    "print(len(cols))\n",
    "for i in range(len(cols)):\n",
    "    print(f'col #{i}, nans: {data[cols[i]].isna().sum() / data.shape[0] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что большая часть пропусков содержится в 68, 69, 73, 74 и 75 колонках, поэтому имеет смысл удалить эти колонки, а потом уже удалить семплы с пропусками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 77)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "X = data.copy()\n",
    "print(data.shape)\n",
    "\n",
    "many_nans = [68, 69, 73, 74, 75]\n",
    "to_del = [list(X)[col_number] for col_number in many_nans]\n",
    "X.drop(to_del, axis=1, inplace=True)\n",
    "X.dropna(axis=0, inplace=True)\n",
    "\n",
    "y = y_init.iloc[X.index]\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим сколько теперь данных было удалено."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples deleted: 108 = 10.00%\n"
     ]
    }
   ],
   "source": [
    "print(f'Total samples deleted: {data.shape[0] - X.shape[0]} = {(data.shape[0] - X.shape[0]) / data.shape[0] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже намного лучше. Следующим шагом будет замена `MinMaxScaler` на `StandardScaler` и применение `FeatureAgglomeration`. `FeatureAgglomeration` - уменьшает количество измерений путем группировки данных по схожести фич, на самом деле именно то, что нужно, ибо изначальная постановка задачи для нашим данных была именно такая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans score: 0.158\n",
      "Gaussian mixture score: 0.174\n",
      "Agglomerative clustering score: 0.174\n"
     ]
    }
   ],
   "source": [
    "data = X.copy()\n",
    "scaler = MinMaxScaler()\n",
    "X[list(X)] = scaler.fit_transform(X)\n",
    "\n",
    "try_km(X, y)\n",
    "try_gm(X, y)\n",
    "try_ac(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну что же, стало только хуже. Возможно это из-за того, что появилось много новых примеров, которые похожи друг на друга и разделить данные стало сложнее.\n",
    "\n",
    "Следующим шагом попробуем уменьшить размерность данных: воспользуемся `FeatureAgglomeration` - работает также как и `AgglomerationClustering`, но для столблцов - объединяет их по схожести. Главным параметром модели является `n_clusters`, которое определяет результируещее количество фич.\n",
    "\n",
    "Переберем параметры от 8 до 45, чтобы найти лучший. Также заменим `MinMaxScaler` на `StandardScaler`, ибо `FeatureAgglomeration` работает с ним лучше (согласно спецификации, да и на практике)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters: 8\n",
      "Kmeans score: 0.151\n",
      "Gaussian mixture score: 0.212\n",
      "Agglomerative clustering score: 0.158\n",
      "\n",
      "n_clusters: 9\n",
      "Kmeans score: 0.153\n",
      "Gaussian mixture score: 0.190\n",
      "Agglomerative clustering score: 0.165\n",
      "\n",
      "n_clusters: 10\n",
      "Kmeans score: 0.160\n",
      "Gaussian mixture score: 0.227\n",
      "Agglomerative clustering score: 0.197\n",
      "\n",
      "n_clusters: 11\n",
      "Kmeans score: 0.151\n",
      "Gaussian mixture score: 0.273\n",
      "Agglomerative clustering score: 0.146\n",
      "\n",
      "n_clusters: 12\n",
      "Kmeans score: 0.152\n",
      "Gaussian mixture score: 0.256\n",
      "Agglomerative clustering score: 0.201\n",
      "\n",
      "n_clusters: 13\n",
      "Kmeans score: 0.140\n",
      "Gaussian mixture score: 0.137\n",
      "Agglomerative clustering score: 0.137\n",
      "\n",
      "n_clusters: 14\n",
      "Kmeans score: 0.127\n",
      "Gaussian mixture score: 0.145\n",
      "Agglomerative clustering score: 0.135\n",
      "\n",
      "n_clusters: 15\n",
      "Kmeans score: 0.139\n",
      "Gaussian mixture score: 0.233\n",
      "Agglomerative clustering score: 0.135\n",
      "\n",
      "n_clusters: 16\n",
      "Kmeans score: 0.147\n",
      "Gaussian mixture score: 0.213\n",
      "Agglomerative clustering score: 0.164\n",
      "\n",
      "n_clusters: 17\n",
      "Kmeans score: 0.134\n",
      "Gaussian mixture score: 0.177\n",
      "Agglomerative clustering score: 0.132\n",
      "\n",
      "n_clusters: 18\n",
      "Kmeans score: 0.170\n",
      "Gaussian mixture score: 0.239\n",
      "Agglomerative clustering score: 0.172\n",
      "\n",
      "n_clusters: 19\n",
      "Kmeans score: 0.174\n",
      "Gaussian mixture score: 0.208\n",
      "Agglomerative clustering score: 0.184\n",
      "\n",
      "n_clusters: 20\n",
      "Kmeans score: 0.177\n",
      "Gaussian mixture score: 0.208\n",
      "Agglomerative clustering score: 0.177\n",
      "\n",
      "n_clusters: 21\n",
      "Kmeans score: 0.163\n",
      "Gaussian mixture score: 0.209\n",
      "Agglomerative clustering score: 0.192\n",
      "\n",
      "n_clusters: 22\n",
      "Kmeans score: 0.159\n",
      "Gaussian mixture score: 0.179\n",
      "Agglomerative clustering score: 0.126\n",
      "\n",
      "n_clusters: 23\n",
      "Kmeans score: 0.157\n",
      "Gaussian mixture score: 0.195\n",
      "Agglomerative clustering score: 0.194\n",
      "\n",
      "n_clusters: 24\n",
      "Kmeans score: 0.172\n",
      "Gaussian mixture score: 0.160\n",
      "Agglomerative clustering score: 0.183\n",
      "\n",
      "n_clusters: 25\n",
      "Kmeans score: 0.165\n",
      "Gaussian mixture score: 0.203\n",
      "Agglomerative clustering score: 0.224\n",
      "\n",
      "n_clusters: 26\n",
      "Kmeans score: 0.189\n",
      "Gaussian mixture score: 0.208\n",
      "Agglomerative clustering score: 0.205\n",
      "\n",
      "n_clusters: 27\n",
      "Kmeans score: 0.190\n",
      "Gaussian mixture score: 0.224\n",
      "Agglomerative clustering score: 0.215\n",
      "\n",
      "n_clusters: 28\n",
      "Kmeans score: 0.184\n",
      "Gaussian mixture score: 0.174\n",
      "Agglomerative clustering score: 0.193\n",
      "\n",
      "n_clusters: 29\n",
      "Kmeans score: 0.173\n",
      "Gaussian mixture score: 0.172\n",
      "Agglomerative clustering score: 0.178\n",
      "\n",
      "n_clusters: 30\n",
      "Kmeans score: 0.162\n",
      "Gaussian mixture score: 0.171\n",
      "Agglomerative clustering score: 0.193\n",
      "\n",
      "n_clusters: 31\n",
      "Kmeans score: 0.163\n",
      "Gaussian mixture score: 0.221\n",
      "Agglomerative clustering score: 0.214\n",
      "\n",
      "n_clusters: 32\n",
      "Kmeans score: 0.171\n",
      "Gaussian mixture score: 0.180\n",
      "Agglomerative clustering score: 0.184\n",
      "\n",
      "n_clusters: 33\n",
      "Kmeans score: 0.174\n",
      "Gaussian mixture score: 0.196\n",
      "Agglomerative clustering score: 0.226\n",
      "\n",
      "n_clusters: 34\n",
      "Kmeans score: 0.168\n",
      "Gaussian mixture score: 0.187\n",
      "Agglomerative clustering score: 0.270\n",
      "\n",
      "n_clusters: 35\n",
      "Kmeans score: 0.167\n",
      "Gaussian mixture score: 0.188\n",
      "Agglomerative clustering score: 0.205\n",
      "\n",
      "n_clusters: 36\n",
      "Kmeans score: 0.181\n",
      "Gaussian mixture score: 0.185\n",
      "Agglomerative clustering score: 0.219\n",
      "\n",
      "n_clusters: 37\n",
      "Kmeans score: 0.178\n",
      "Gaussian mixture score: 0.169\n",
      "Agglomerative clustering score: 0.223\n",
      "\n",
      "n_clusters: 38\n",
      "Kmeans score: 0.170\n",
      "Gaussian mixture score: 0.198\n",
      "Agglomerative clustering score: 0.154\n",
      "\n",
      "n_clusters: 39\n",
      "Kmeans score: 0.181\n",
      "Gaussian mixture score: 0.207\n",
      "Agglomerative clustering score: 0.165\n",
      "\n",
      "n_clusters: 40\n",
      "Kmeans score: 0.177\n",
      "Gaussian mixture score: 0.187\n",
      "Agglomerative clustering score: 0.164\n",
      "\n",
      "n_clusters: 41\n",
      "Kmeans score: 0.198\n",
      "Gaussian mixture score: 0.180\n",
      "Agglomerative clustering score: 0.169\n",
      "\n",
      "n_clusters: 42\n",
      "Kmeans score: 0.176\n",
      "Gaussian mixture score: 0.162\n",
      "Agglomerative clustering score: 0.174\n",
      "\n",
      "n_clusters: 43\n",
      "Kmeans score: 0.191\n",
      "Gaussian mixture score: 0.185\n",
      "Agglomerative clustering score: 0.214\n",
      "\n",
      "n_clusters: 44\n",
      "Kmeans score: 0.172\n",
      "Gaussian mixture score: 0.168\n",
      "Agglomerative clustering score: 0.184\n",
      "\n",
      "n_clusters: 45\n",
      "Kmeans score: 0.190\n",
      "Gaussian mixture score: 0.213\n",
      "Agglomerative clustering score: 0.221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data[list(data)] = scaler.fit_transform(data)\n",
    "\n",
    "for i in range(8, 46):\n",
    "    print(f'n_clusters: {i}')\n",
    "    data_copy = data.copy()\n",
    "    model = FeatureAgglomeration()\n",
    "    params = {\n",
    "        'n_clusters': i\n",
    "    }\n",
    "    \n",
    "    model = model.set_params(**params)\n",
    "    data_copy = model.fit_transform(data_copy)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    data_copy = pd.DataFrame(data_copy)\n",
    "    \n",
    "    try_km(data_copy, y)\n",
    "    try_gm(data_copy, y)\n",
    "    try_ac(data_copy, y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Больше внимания стоит уделить модели `GaussianMixture` потому что она дает самый лучший результат (0.273), а также у нее есть параметры, которые мы можем поменять, чтобы улучшить точность модели.\n",
    "- `n_init` - количество инициализаций алгоритма, обычно ~20 хватает для оптимального значения;\n",
    "- `covariance_type` - определяет тип ковариационной матрицы для компонент, попробуем значение **tied**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters: 8\n",
      "Gaussian mixture score: 0.263\n",
      "\n",
      "n_clusters: 9\n",
      "Gaussian mixture score: 0.290\n",
      "\n",
      "n_clusters: 10\n",
      "Gaussian mixture score: 0.246\n",
      "\n",
      "n_clusters: 11\n",
      "Gaussian mixture score: 0.261\n",
      "\n",
      "n_clusters: 12\n",
      "Gaussian mixture score: 0.216\n",
      "\n",
      "n_clusters: 13\n",
      "Gaussian mixture score: 0.262\n",
      "\n",
      "n_clusters: 14\n",
      "Gaussian mixture score: 0.300\n",
      "\n",
      "n_clusters: 15\n",
      "Gaussian mixture score: 0.249\n",
      "\n",
      "n_clusters: 16\n",
      "Gaussian mixture score: 0.293\n",
      "\n",
      "n_clusters: 17\n",
      "Gaussian mixture score: 0.335\n",
      "\n",
      "n_clusters: 18\n",
      "Gaussian mixture score: 0.340\n",
      "\n",
      "n_clusters: 19\n",
      "Gaussian mixture score: 0.250\n",
      "\n",
      "n_clusters: 20\n",
      "Gaussian mixture score: 0.296\n",
      "\n",
      "n_clusters: 21\n",
      "Gaussian mixture score: 0.260\n",
      "\n",
      "n_clusters: 22\n",
      "Gaussian mixture score: 0.359\n",
      "\n",
      "n_clusters: 23\n",
      "Gaussian mixture score: 0.257\n",
      "\n",
      "n_clusters: 24\n",
      "Gaussian mixture score: 0.251\n",
      "\n",
      "n_clusters: 25\n",
      "Gaussian mixture score: 0.390\n",
      "\n",
      "n_clusters: 26\n",
      "Gaussian mixture score: 0.260\n",
      "\n",
      "n_clusters: 27\n",
      "Gaussian mixture score: 0.331\n",
      "\n",
      "n_clusters: 28\n",
      "Gaussian mixture score: 0.298\n",
      "\n",
      "n_clusters: 29\n",
      "Gaussian mixture score: 0.383\n",
      "\n",
      "n_clusters: 30\n",
      "Gaussian mixture score: 0.255\n",
      "\n",
      "n_clusters: 31\n",
      "Gaussian mixture score: 0.229\n",
      "\n",
      "n_clusters: 32\n",
      "Gaussian mixture score: 0.265\n",
      "\n",
      "n_clusters: 33\n",
      "Gaussian mixture score: 0.386\n",
      "\n",
      "n_clusters: 34\n",
      "Gaussian mixture score: 0.285\n",
      "\n",
      "n_clusters: 35\n",
      "Gaussian mixture score: 0.460\n",
      "\n",
      "n_clusters: 36\n",
      "Gaussian mixture score: 0.283\n",
      "\n",
      "n_clusters: 37\n",
      "Gaussian mixture score: 0.348\n",
      "\n",
      "n_clusters: 38\n",
      "Gaussian mixture score: 0.265\n",
      "\n",
      "n_clusters: 39\n",
      "Gaussian mixture score: 0.319\n",
      "\n",
      "n_clusters: 40\n",
      "Gaussian mixture score: 0.341\n",
      "\n",
      "n_clusters: 41\n",
      "Gaussian mixture score: 0.298\n",
      "\n",
      "n_clusters: 42\n",
      "Gaussian mixture score: 0.370\n",
      "\n",
      "n_clusters: 43\n",
      "Gaussian mixture score: 0.326\n",
      "\n",
      "n_clusters: 44\n",
      "Gaussian mixture score: 0.351\n",
      "\n",
      "n_clusters: 45\n",
      "Gaussian mixture score: 0.343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(8, 46):\n",
    "    print(f'n_clusters: {i}')\n",
    "    data_copy = data.copy()\n",
    "    model = FeatureAgglomeration()\n",
    "    params = {\n",
    "        'n_clusters': i\n",
    "    }\n",
    "    \n",
    "    model = model.set_params(**params)\n",
    "    data_copy = model.fit_transform(data_copy)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    data_copy = pd.DataFrame(data_copy)\n",
    "    \n",
    "    try_gm(data_copy, y, **{\n",
    "        'n_init': 20,\n",
    "        'covariance_type': 'tied'\n",
    "    })\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, изменение параметров очень сильно улучшило качество модели (0.273 -> 0.460), что уже является приемлемым качеством, учитывая сложность задачи.\n",
    "\n",
    "## Вывод\n",
    "В ходе выполнения лабораторной работы были разобраны:\n",
    "- 3 различные модели кластеризации (`Kmeans`, `GaussianMixture`, `AgglomerativeClustering`);\n",
    "- способ уменьшения размерности/избыточности данных - `FeatureAgglomeration`;\n",
    "- тюнинг параметров для улучшения точности модели.\n",
    "В итоге удалось поднять изначальную лучшую точность среди трех моделей 0.205 до 0.460, что является более чем 2-ух кратным увеличением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
