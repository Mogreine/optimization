{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4\n",
    "## Задание\n",
    "1. Написать программу, которая разделяет исходную выборку на обучающую и тестовую (training set, validation set, test set), если такое разделение не предусмотрено предложенным набором данных.\n",
    "2. Произвести масштабирование признаков (scaling).\n",
    "3. С использованием библиотеки scikit-learn обучить 2 модели нейронной сети (Perceptron и MLPClassifier) по обучающей выборке.\n",
    "4. Проверить точность модели по тестовой выборке.\n",
    "5. Провести эксперименты и определить наилучшие параметры коэффициента обучения, параметра регуляризации, функции оптимизации.\n",
    "\n",
    "Данные: Pen-Based Recognition of Handwritten Digits.\n",
    "\n",
    "## Ход работы\n",
    "Как обычно импортируем нужные для работы библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "from typing import Tuple\n",
    "from numpy import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, Perceptron\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "target_feature = 'number'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 1\n",
    "Данные даны уже в разделенном виде, так что остается только прочитать их и разделить фичи от целевого значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Reading data')\n",
    "X_train = pd.read_csv('../../data/lab4_train.csv')\n",
    "X_test = pd.read_csv('../../data/lab4_test.csv')\n",
    "\n",
    "y_train = X_train[target_feature]\n",
    "y_test = X_test[target_feature]\n",
    "\n",
    "X_train.drop([target_feature], axis=1, inplace=True)\n",
    "X_test.drop([target_feature], axis=1, inplace=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 2\n",
    "Для нормализации данных используем `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_size = X_train.shape[0]\n",
    "\n",
    "data = pd.concat([X_train, X_test], axis=0)\n",
    "data.dropna(axis=0, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[list(data)] = scaler.fit_transform(data)\n",
    "\n",
    "X_train, X_test = data.iloc[:train_size, :], data.iloc[train_size:, :]\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 3-4\n",
    "Сначала обучим и проверим точность `Perceptron`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic perceptron's score: 87.99\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron(n_jobs=-1, verbose=0, random_state=7)\n",
    "model.fit(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(\"Basic perceptron's score: {:.2f}\".format(test_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что даже обычный перцептрон дает неплохие результаты для распознавания рукописных цифр.\n",
    "\n",
    "Теперь же проверим `MLPClassifier`. Предполагается, что эта модель будет лучше, ибо это по сути каскад слоев из перцептронов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic MLP score: 97.06\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(verbose=0, random_state=7)\n",
    "model.fit(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print('Basic MLP score: {:.2f}'.format(test_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, модель не только дает очень хороший результат, но и значительно точнее `Perceptron`.\n",
    "\n",
    "### Пункт 5\n",
    "Теперь давайте попробуем улучшить результат обоих моделей с помощью подбора более оптимальных параметров моделей.\n",
    "\n",
    "Проще всего поступить следующим образом: напишем функцию, которая будет принимать на вход модель для тюнинга параметров, начальные параметры модели и различные значения параметров, которые нужно проверить. Имея такую функцию все что нужно будет сделать это вызвать ее сначала для 1 модели, а потом для другой - получается в 2 раза меньше кода. Назовем функцию `find_best_params`.\n",
    "\n",
    "Внутри нашей функции необходимо написать еще одну функцию, которая будет проверять значения 1 конкретного параметра, остальные же будут неизменны. На выход она будет давать `map` наиболее оптимальных параметров на данный момент. Назовем функцию `test_param`.\n",
    "\n",
    "Таким образом, алгоритм функции `find_best_params` сводится к тому, чтобы запустить функцию `test_param` от всех параметров, каждый раз обновляя базовые параметры модели, чтобы новые параметры проверялись уже с учетом оптимизации других."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_params(testing_model, model_name: str, base_params: map, param_options: map) -> map:\n",
    "\n",
    "    def test_param(base_params: map, param_name: str, param_options: list) -> map:\n",
    "        print(f'Testing {param_name}')\n",
    "        results = []\n",
    "        for param in param_options:\n",
    "            model = testing_model()\n",
    "            curr_params = base_params\n",
    "            curr_params[param_name] = param\n",
    "            model = model.set_params(**curr_params)\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            score = model.score(X_test, y_test)\n",
    "            print('{:s} {:s}: {}, score: {:.2f}'.format(model_name, param_name, param, score * 100))\n",
    "            results.append(score)\n",
    "        new_params = base_params\n",
    "        new_params[param_name] = param_options[np.argmax(results)]\n",
    "        return new_params\n",
    "\n",
    "    for param, val in param_options.items():\n",
    "        base_params = test_param(base_params, param, val)\n",
    "        \n",
    "    return base_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь опишем параметры, которые будет оптимизировать.\n",
    "\n",
    "**Perceptron**:\n",
    "- `penalty` - тип регуляризации;\n",
    "- `max_iter` - максимальное количество итераций до остановки алгоритма;\n",
    "- `alpha` - регуляризационный коэффициент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing penalty\n",
      "Perceptron penalty: elasticnet, score: 82.10\n",
      "Perceptron penalty: l1, score: 86.65\n",
      "Perceptron penalty: l2, score: 82.10\n",
      "Perceptron penalty: None, score: 87.99\n",
      "Testing max_iter\n",
      "Perceptron max_iter: 200, score: 87.99\n",
      "Perceptron max_iter: 400, score: 87.99\n",
      "Perceptron max_iter: 600, score: 87.99\n",
      "Perceptron max_iter: 800, score: 87.99\n",
      "Perceptron max_iter: 1000, score: 87.99\n",
      "Perceptron max_iter: 1500, score: 87.99\n",
      "Perceptron max_iter: 2000, score: 87.99\n",
      "Perceptron max_iter: 6000, score: 87.99\n",
      "Testing alpha\n",
      "Perceptron alpha: 0.0001, score: 87.99\n",
      "Perceptron alpha: 0.001, score: 87.99\n",
      "Perceptron alpha: 0.01, score: 87.99\n",
      "Perceptron alpha: 0.1, score: 87.99\n",
      "Perceptron alpha: 0.3, score: 87.99\n",
      "Perceptron alpha: 0.6, score: 87.99\n",
      "Perceptron alpha: 0.8, score: 87.99\n",
      "Perceptron alpha: 1, score: 87.99\n",
      "Perceptron alpha: 1.5, score: 87.99\n",
      "Perceptron alpha: 3, score: 87.99\n"
     ]
    }
   ],
   "source": [
    "perceptron_base_params = {\n",
    "    'random_state': 7,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': 0,\n",
    "    'penalty': 'None'\n",
    "}\n",
    "perceptron_option_params = {\n",
    "    'penalty': ['elasticnet', 'l1', 'l2', 'None'],\n",
    "    'max_iter': [200, 400, 600, 800, 1000, 1500, 2000, 6000],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 0.1, 0.3, 0.6, 0.8, 1, 1.5, 3]\n",
    "}\n",
    "perceptron_best_params = find_best_params(Perceptron, 'Perceptron', perceptron_base_params, perceptron_option_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLPClassifier**\n",
    "- `solver` - функция оптимизации весов;\n",
    "- `max_iter` - максимальное количество итераций до сходимости;\n",
    "- `hidden_layer_sizes` - размер скрытых слоев;\n",
    "- `alpha` - регуляризационный коэффициент L2.\n",
    "- `learning_rate` - определяет то, как изменяется обучающий коэффициент во время оптимизации;\n",
    "- `learning_rate_init` - изначальный обучающий коэффициент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hidden_layer_sizes\n",
      "MPL hidden_layer_sizes: (16, 32), score: 97.03\n",
      "MPL hidden_layer_sizes: (32, 64), score: 97.06\n",
      "MPL hidden_layer_sizes: (64, 128), score: 97.06\n",
      "MPL hidden_layer_sizes: (128, 256), score: 97.40\n",
      "Testing max_iter\n",
      "MPL max_iter: 650, score: 97.40\n",
      "MPL max_iter: 800, score: 97.40\n",
      "MPL max_iter: 1000, score: 97.40\n",
      "Testing alpha\n",
      "MPL alpha: 0.0001, score: 97.40\n",
      "MPL alpha: 0.001, score: 97.37\n",
      "MPL alpha: 0.01, score: 97.20\n",
      "MPL alpha: 0.08, score: 97.51\n",
      "MPL alpha: 0.1, score: 97.46\n",
      "MPL alpha: 0.2, score: 97.23\n",
      "MPL alpha: 0.3, score: 97.11\n",
      "MPL alpha: 0.6, score: 96.86\n",
      "Testing learning_rate\n",
      "MPL learning_rate: adaptive, score: 97.51\n",
      "MPL learning_rate: constant, score: 97.51\n",
      "MPL learning_rate: invscaling, score: 97.51\n",
      "Testing learning_rate_init\n",
      "MPL learning_rate_init: 0.0001, score: 97.37\n",
      "MPL learning_rate_init: 0.001, score: 97.51\n",
      "MPL learning_rate_init: 0.003, score: 97.48\n",
      "MPL learning_rate_init: 0.01, score: 96.54\n",
      "MPL learning_rate_init: 0.1, score: 95.80\n",
      "MPL learning_rate_init: 0.15, score: 92.31\n"
     ]
    }
   ],
   "source": [
    "mlp_base_params = {\n",
    "    'random_state': 7,\n",
    "    'verbose': 0,\n",
    "    'max_iter': 650\n",
    "}\n",
    "mlp_option_params = {\n",
    "    'hidden_layer_sizes': [(16, 32), (32, 64), (64, 128), (128, 256)],\n",
    "    'max_iter': [650, 800, 1000],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 0.08, 0.1, 0.2, 0.3, 0.6],\n",
    "    'learning_rate': ['adaptive', 'constant', 'invscaling'],\n",
    "    'learning_rate_init': [1e-4, 1e-3, 3e-3, 1e-2, 0.1, 0.15]\n",
    "}\n",
    "\n",
    "mlp_best_params = find_best_params(MLPClassifier, 'MPL', mlp_base_params, mlp_option_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим точность моделей с новыми параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best perceptron's score: 87.99\n",
      "Best MLP's score: 97.51\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron()\n",
    "model.set_params(**perceptron_best_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(\"Best perceptron's score: {:.2f}\".format(test_score * 100))\n",
    "\n",
    "model = MLPClassifier()\n",
    "model.set_params(**mlp_best_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(\"Best MLP's score: {:.2f}\".format(test_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге получилось улучшить точность `MLPClassifier` 97.07 -> 97.51, с `Perceptron` такого сделать не получилось - точность осталась на том же уровне не смотря на тюнинг параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "В ходе выполнения лабораторной работы были разобраны модели `Perceptron` и `MLPClassifier`. В ходе оптимизации параметров моделей удалось улучшить качество `MLPClassifier`, точность `Perceptron` осталась на прежнем уровне."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
